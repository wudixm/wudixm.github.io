## 教程

[原文](https://www.youtube.com/watch?v=JUq1N8NClcg&list=PLmOn9nNkQxJEDjzl0iBYZ3WuXUuUStxZl&index=3)

## 分布式原理

服务端的负载均衡，有负载均衡器
客户端的负载均衡，有注册中心，一次返回所有可用server 列表，在客户端决定请求哪个server

协调调度中心(注册中心) zookeeper

## flume缺点

flume 是传输框架，不是存储框架

- 数据都保存在内存中，数据容易丢失
- 增加消费者不容易
- 数据无法长时间保留

## kafka

### 消息列表

每个系统只从消息系统中获取它们关心的数据

为什么需要消息队列
- 解释--把消息的生产，消费和数据存储，分解开，耦合性越低，扩展性越强
- 冗余--数据的健壮性，数据会多存几份(备份、副本)，可用性强
- 扩展性--当前机器性能不够了，再加一台机器就可以了，跟分布式有关系 
- 灵活性&峰值处理--可以均衡速率，是消费者去取
- 可恢复性--机器down掉了，一会又好了，可以恢复
- 保证顺序--顺序保证的前提是同一个生产者，消息放到一个机器上，不能分开放到多个机器，多个机器内的消息，不保证顺序
- 缓冲
- 异步通信--说到异步肯定是有多个线程，异步，我发了个消息，不需要等待，我就可以干其它事，就是异步，如果发了消息，需要等待，就是同步

### 方案

- 点对点模式---一对一，消费者主动拉取数据，消息收到后消息清除
- 发布/订阅模式---一对多，数据生产后，推送给所有订阅者

### 什么是kafka

- 在流式计算中，kafka一般用来缓存数据，可以重复读取，重复消费
- 由linkedIn 公司开发，2011年初开源，目标是为处理实时数据提供一个统一、高通量、低等待的平台
- 是一个分布式消息队列。对消息保存时，根据topic进行归类，发送消息称为producer，消息接受者称为consumer，kafka集群有多个kafka实例组成，每个实例(server) 称为broker
- kafka集群和consumer 都依赖于zk 集群，保存一些meta信息，来保证系统的可用性

### 概念

Producer: 消息生产者，就是向kafka broker发消息的客户端
Consumer: 消息消费者，向kafka broker取消息的客户端
Topic： 可以理解为一个队列
Consumer Group(CG): 这是kafka 用来实现一个topic消息的广播(发送给所有的consumer)和单播(发送给任意一个consumer) 的手段。一个topic可以有多个CG，但每个partition只会把消息发给该CG中的一个consumer，如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。
Broker: 一台kafka服务器就是一个broker，一个集群由多个broker组成，一个broker可以容纳多个topic
Partition: 为了实现扩展性，一个非常大的topic可以分布到多个broker上，一个topic可以分为多个partition，每个partition是一个有序的队列，partition中的每条消息都会被分配到一个有序的id(offset)，kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体(多个partition间)的顺序。**要考虑业务当中需不需要保证顺序，如果不需要保证顺序，可以放到多个partition中，需要保证顺序，只能放一个partition中**。
Offset: kfaka的存储文件都是按照offset.kfaka来命名，用offset做名字的好处是方便查找。

#### 如何增加消费能力
增加partition，再增加consumer。只增加consumer 没用，多余的consumer只是等待。 

#### zk 作用

- 协调调度
- 消费者消费到哪一条了，需要保存在zk 中，下一次访问的时候，可以从指定的位置开始。或者从头再读也可以实现，改offset


### kafka 命令行操作

```sh
bin/kafka-topics.sh --zookeeper localhost:2181 --list
# partitions 定义分区数，replication-factor 定义副本数
bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic first --partitions 3 --replication-factor 2 

# 当前信息
# 查看leader是谁
bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic first

# 删除topic
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic first

# 发送消息
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic first

# 消费消息
# from-begining 每次从头读取
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-begining --topic first

```

## kafka 生产过程分析

### 写入方式

producer采用推(push)模式将消息发布到broker，每条消息都被追加(append)到分区(partition) 中，属于顺序写磁盘(顺序写磁盘效率比随机写内存要高，保障kafka吞吐率)

#### 高吞吐量

- kafka顺序写日志
- kafka零复制，redis 在处理rdb 的时候，用的fork()命令，还有写时复制技术，JUC，copyonwriteArraylist, copyonwriteSet
- kafka分段日志，segments
- kafkfa 预读(Read ahead)，后写(Write Behind)

#### offset

0000000000.log ==> 1G 里面有10 个offset
0000000010.log ==> 1G offset从11 开始
0000000020.log ==> 1G offset从21 开始

#### 后写write behind

空闲内存做为磁盘缓存

### 分区(partition)

消息发送时都被发送到一个topic，其本质就是一个目录，而topic是由一些partition logs(分区日志)组成
kafka分区文件夹命名规则：topic + "_" + 分区号
每个partition中的消息都是有序的，生产的消息被不断追加到partition log 上，其中的每一个消息都被赋予了一个唯一的offset值

#### 分区的原因

- 方便在集群中扩展，每个partition可以通过调整以适应它所在的机器，而一个topic又可以有多个partition组成。因此整个集群就可以适应任意大小的数据了
- 可以提高并发，因为可以以partition为单位读写了

#### 分区的原则

- 指定了分区，直接放到指定分区中
- 未指定分区，但指定了key，通过key的value进行hash 出一个Partition
- 分区和key都未指定，使用轮询选出一个分区 

#### .index 文件

举例：
log 文件是
1adfadafd2fdsafdsa3fdafdsa

index文件内容就是
1 0
2 10

### replication，副本

同一个partition可能会有多个replication(对应server.properties配置中的default.repllication.factor=N)。没有replication的情况下，一旦broker down掉，其上所有partition数据都不可被消费，同时producer也不能再将数据存于其上。
引入replication之后，同一个partition可能会有多个replication, 而这时需要在这些replication之间选出一个leader，producer和consumer只与这个leader交互，其它replication作为follower从leader 中取数据，复制备份。

### 写入流程

kafka生产数据时的应答机制(ACK)
- 取值为0：生产者发送完数据，不关心数据是否到达kafka，然后直接发送下一条数据，效率非常高，但是数据丢失可能性非常大
- 取值为1：生产者发送完数据，等待leader应答，如果完成，才能发送下一条数据，不关心数据是否到达follower，这种场合性能会慢一些，数据比较安全。但是在leader保存成功后，突然down掉，follower没来得及获取数据，那么数据就会丢失。
- 取值为-1(all)：生产者发送完数据，需要等待所有副本的应答(leader+follower)，这种方式最安全，但是性能非常差

### 数据保存

#### key value

[原文](https://stackoverflow.com/questions/40872520/whats-the-purpose-of-kafkas-key-value-pair-based-messaging)
Kafka uses the abstraction of a distributed log that consists of partitions. Splitting a log into partitions allows to scale-out the system.

Keys are used to determine the partition within a log to which a message get's appended to. While the value is the actual payload of the message. The examples are actually not very "good" with this regard; usually you would have a complex type as value (like a tuple-type or a JSON or similar) and you would extract one field as key.

See: http://kafka.apache.org/intro#intro_topics and http://kafka.apache.org/intro#intro_producers

In general the key and/or value can be null, too. If the key is null a random partition will the selected. If the value is null it can have special "delete" semantics in case you enable log-compaction instead of log-retention policy for a topic (http://kafka.apache.org/documentation#compaction).

