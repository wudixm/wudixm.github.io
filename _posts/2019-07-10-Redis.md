## 命令

### ttl

当 key 不存在时，返回 -2 。 当 key 存在但没有设置剩余生存时间时，返回 -1 。 否则，以毫秒为单位，返回 key 的剩余生存时间。

注意：在 Redis 2.8 以前，当 key 不存在，或者 key 没有设置剩余生存时间时，命令都返回 -1 。

### 事务

示例以下示例说明了如何启动和执行Redis事务。

```
redis 127.0.0.1:6379> MULTI
OK
redis 127.0.0.1:6379> SET mykey "redis"
QUEUED
redis 127.0.0.1:6379> GET mykey
QUEUED
redis 127.0.0.1:6379> INCR visitors
QUEUED
redis 127.0.0.1:6379> EXEC
1) OK
2) "redis"
3) (integer) 1
```

### redis 事务命令

下表列出了与Redis事务相关的一些基本命令。
|序号|命令|说明|
|----|----|----|
|1 |discard |丢弃在MULTI之后发出的所有命令 |
|2|exec|执行MULTI后发出的所有命令|
|3|multi|标记事务块的开始|
|4|unwatch|取消 WATCH 命令对所有 key 的监视|
|5|WATCH key [key …]|监视给定的键以确定MULTI / EXEC块的执行|

### LRU Cache算法以及在redis中的应用

[原文](https://zhuanlan.zhihu.com/p/40354122)

覆盖一个现存的块的时候会使用替换策略，替换策略有很多种，主要有：
- LRU - Least Recently Used
LRU是很常用的替换策略，通常的实现会有一个age counter（替换index）与每个数组S相关。这个counter最大值就是S，当一个set被访问到，那么比它低的counter就被置为0，其他set自增1。
- FIFO - First-In First-Out
先进先出策略。
- LFU – Least Frequently Used
很高效的算法，但很耗资源，通常不用。
- Round-robin
有一个指针指向将要被替换的行，当行被替换，指针就会自增1，指针是环形的。
- Random
随机策略，用于全相联高速缓存。每个时序Round-robin就要更新，而不是每个替换操作。

### linux中的文件描述符(file descriptor)和文件
[原文](https://www.jianshu.com/p/504a53c30c17)

linux为了实现一切皆文件的设计哲学，不仅将数据抽象成了文件，也将一切操作和资源抽象成了文件，比如说硬件设备，socket，磁盘，进程，线程等。
这样的设计将系统的所有动作都统一起来，实现了对系统的原子化操作，大大降低了维护和操作的难度，想想看，对于socket，硬件设备，我们只要读读写写文件就能对其进行操作是多么爽的一件事

那么在操作这些所谓的文件的时候，我们不可能没操作一次就要找一次名字吧，这样会耗费大量的时间和效率。咱们可以每一个文件操作一个索引，这样，要操作文件的时候，我们直接找到索引就可以对其进行操作了。我们将这个索引叫做文件描述符（file descriptor），简称fd，在系统里面是一个非负的整数。每打开或创建一个文件，内核就会向进程返回一个fd，第一个打开文件是0,第二个是1,依次递增。

我们平时说的命令如./test.sh>res2.log 2>&1就是将标准和错误的输出流重定向到log文件里面，通常情况下系统启动后会自动启动文件描述符号0,1,2，当然，你也可以关闭这几个文件描述符，比如关掉1,然后打开一个文件，那么到时候你使用代码中的printf就不会输出到终端，而是会输入到你打开的文件里面（这样在测试的时候免去了我们在代码里面写log的麻烦）

在python中可以用如下拿到fd，在linux下fd叫做文件描述符，在window下fd叫做句柄，所以这就说明了为啥在官方文档中fileno解释是Return the file descriptor or handle used by the connection.

在linux内核中通常会有个task_struct结构体来维护进程相关的表，叫进程控制块，这个块里面会有指针指向file_struct的结构体，称为文件描述表，文件描述符就是这个表的索引。

而这个file_struct会指向一个file的结构体，一般情况下，进程是没有办法直接访问文件的，只能通过文件描述表里面的文件描述符找到文件。file有几个主要的结构体成员，分别是count，file_operation和dentry（directory entry）。
count：这个是引用计数，像上面的pipe，还有fork，dup等的文件描述符可能会指向同一个file，比如现在有fd1和fd2，他们都指向了同一个文件，那么这个文件的计数就是2,要想关闭这个文件，close（fd1）是不能关掉的，因为这个时候计数为1,只有在计数为0的时候才算完全关闭
file_operation：这个指向的文件操作指针，file_operation里面包含了对文件操作的内核函数指针，他指向内核操作函数，比如说read，write，release，open，当然，不同的文件file_opertions有不同的操作，像读取字符设备的文件操作肯定不会和读取正常文件的一样，他们不是读取磁盘，而是读取硬件设备
dentry：目录项，一个指向带有文件路径的dentry结构体指针，我们在操作文件时，一定要知道他的路径，才能进行操作。为了减少读盘次数,内核缓存了目录的树状结构,称为dentry cache,其中每个节点是一 个dentry结构体,只要沿着路径各部分的dentry搜索即可。

现在看下dentry这个结构体指向了什么？
dentry指向了inode，inode是一个包含所有者、文件大小、文件类型和权限位，创建、修改和更新时间等的结构体，保存着从磁盘inode读上来的信息。里面还有两个重要的成员：
分别是inode_opertions和super_block
inode_opertions：是描述文件能进行哪些操作的结构体，他指向了文件操作的内核函数，比如说rm，mkdir，mv等，
super_block：保存着从磁盘分区的超级块读上来的信息，像文件系统类型（比如说是ext2，ext3等），块大小，不同的文件类型，底层的实现是不同的。当然，super_block还有s_root个成员指向了dentry，因为他需要知道文件的根目录被mount 到哪里
file 、dentry、inode 、super_block这几个结构体组成了VFS的核心概念

### redis ziplist redis源码之压缩列表ziplist

[原文](https://blog.csdn.net/qiangzhenyi1207/article/details/80353104)
连续，无序的数据结构。压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。

### key notification redis数据库通知

[原文](https://www.cnblogs.com/zhangchao-letv/articles/6121635.html)
数据库通知是Redis2.8版本新增加的功能,这个功能可以让客户端通过订阅给定的频道或者模式,来获知数据库中键的变化,以及数据库中命令的执行情况。
举个例子,以下代码展示了客户端如何获取0号数据库中针对message键执行的所有命令:

```
127.0.0.1:6379>SUBSCRIBE__keyspace@0__:message
Reading messages . . . (press Ctrl-C to quit)
1) "subscribe"            //订阅信息
2) "_ _keyspace@0_:message"
3) (integer) 1
1) "message" //执行SET 命令
2) "_ _keyspace@0_: message"
3) "set"
1) "message" //执行EXPIE命令
2) " keyspace@0_:message"
3) "expire"
1) "message" //执行DEL 命令
2) "_ _keyspace@0_: message "
3) "de1"
```
根据发回的通知显示，先后共有SET、EXPlRE 、DEL 三个命令对键message进行了操作。

这一类关注"某个键执行了什么命令"的通知称为键空间通知(key-space-notification),除此之外，还有另一类称为键事件通知(key-event-notification)的通知,它们关注的是"某个命令被什么键执行了" 。
以下是一个键事件通知的例子，代码展示了客户端如何获取0 号数据库中所有执行DEL 命令的键:

```
127.0 . 0.1:6379> SUBSCRIBE_ _keyevent@0_ _:de1
Reading messages. . . (press Ctrl-C to quit)
1) "subcribe"                      //订阅信息
2) "_ _keyevent@0_ _:del"
3) (integer) 1

1) "message"                     //键key执行了DEL命令
2) "keyevent@0_ _:del"
3) "key"

1) "message"                     //键number执行了DEL命令
2) "_ _keyevent@0_ _:del"
3) "number"

1) "message"                     //键message执行了DEL命令
2) "keyevent@0_ _:del"
3) "message"

```

### scan 遍历
SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。

当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。

### keys 命令

Returns all keys matching pattern.  Redis running on an entry level laptop can scan a 1 million key database in 40 milliseconds.

Warning: consider KEYS as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don't use KEYS in your regular application code. If you're looking for a way to find keys in a subset of your keyspace, consider using SCAN or sets.

### xadd 命令

XADD key ID field string [field string ...]

### zset 与skiplist 数据结构

```C
/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
    sds ele;
    double score;
    struct zskiplistNode *backward;
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned long span;
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;
    unsigned long length;
    int level;
} zskiplist;

typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
```

### skiplist 实现zset

[原文](https://blog.csdn.net/weixin_41462047/article/details/81253106)

听到跳表（skiplist）这个名字，既然是list，那么应该跟链表有关。 
跳表是有序链表，但是我们知道，即使对于排过序的链表，我们对于查找还是需要进行通过链表的指针进行遍历的，时间复杂度很高依然是O(n)，这个显然是不能接受的。是否可以像数组那样，通过二分法进行查找呢，但是由于在内存中的存储的不确定性，不能这做。

但是我们可以结合二分法的思想，没错，跳表就是链表与二分法的结合。 
1.链表从头节点到尾节点都是有序的 
2.可以进行跳跃查找（形如二分法），降低时间复杂度

一个有序的链表，我们选取它的一半的节点用来建索引，这样如果插入一个节点，我们比较的次数就减少了一半。这种做法，虽然增加了50%的空间，但是性能提高了一倍。如上图。

既然，我们已经提取了一层节点索引，那么，可以在第一层索引上再提取索引。如下图。

#### 查询

当targetNode->next[i]的值 < 待查找的值时，令targetNode = targetNode->next[i]，targetNode移到第i级的下一个结点； 
当targetNode->next[i]的值 > 待查找的值时，向下降级，i- - ，不改变targetNode； 
当targetNode->next[i]的值 = 待查找的值时，向下降级，i- - ，不改变targetNode。

最后，再次比较targetNode->next[0]和theElement，判断是否找到。 
所以整个运算下来，targetNode是要查找的节点前面那个节点。

#### 插入 
当有2级索引时，新的节点先和2级索引比较，再和1级索引比较，最后和原链表比较，最终插到原链表中。当节点很多时，比较次数是原来的四分之一。

当然，当节点足够多的时候，我们还可以继续加索引，保证每一层索引数是低级索引的一半。当这一层只剩两个节点时，就没有必要再建索引了，因为一个节点没有比较的意义。

当很多节点插入时，上层索引节点已经不够用，我们需要在新节点中选取一部分节点提到上一层，跳表的设计者用“抛硬币”的方法选取节点是否提拔，也就是随机的方式，每个节点有50%概率会提拔。这样虽然不会让索引绝对均匀分布，但也会大体上是均匀的。

综上,插入的步骤：

新节点和各层索引节点逐一比较，确定原链表的插入位置。O（logN）
把索引插入到原链表。O（1）
利用抛硬币的随机方式，决定新节点是否提升为上一级索引。结果为“正”则提升并继续抛硬币，结果为“负”则停止。O（logN）
总体上，跳表插入操作的时间复杂度是O（logN），而这种数据结构所占空间是2N，既空间复杂度是 O（N）。

#### 删除

自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。O（logN）
删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）。O（logN）
总体上，跳表删除操作的时间复杂度是O（N）。

#### 应用 
Redis当中的Sorted-set这种有序的集合，正是对于跳表的改进和应用。

相比于二叉查找树，跳表维持结构平衡的成本比较低，完全靠随机。而二叉查找树需要Rebalance来重新调整平衡的结构。 

#### 相比hash 和红黑树优点

如果要实现一个key-value结构，需求的功能有插入、查找、迭代、修改，那么首先Hash表就不是很适合了，因为迭代的时间复杂度比较高；而红黑树的插入很可能会涉及多个结点的旋转、变色操作，因此需要在外层加锁，这无形中降低了它可能的并发度。而SkipList底层是用链表实现的，可以实现为lock free，同时它还有着不错的性能（单线程下只比红黑树略慢），非常适合用来实现我们需求的那种key-value结构。

### zrangebyscore

ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]

```shell
Parse the min-max interval. If one of the values is prefixed
by the "(" character, it's considered "open". For instance
ZRANGEBYSCORE zset (1.5 (2.5 will match min < x < max
ZRANGEBYSCORE zset 1.5 2.5 will instead match min <= x <= max */


127.0.0.1:6379[1]> ZRANGEBYSCORE za 8 (8.1 limit 0 10
1) "first"
2) "s"
127.0.0.1:6379[1]> ZRANGEBYSCORE za 8 9 limit 0 10
1) "first"
2) "s"
3) "s2"
4) "s3"
127.0.0.1:6379[1]> ZRANGEBYSCORE za 8 9 limit 0 10 withscores
1) "first"
2) "8.0800000000000001"
3) "s"
4) "8.0899999999999999"
5) "s2"
6) "8.0999999999999996"
7) "s3"
8) "8.1099999999999994"
```

### setbit

SETBIT key offset value

Sets or clears the bit at offset in the string value stored at key.

The bit is either set or cleared depending on value, which can be either 0 or 1. When key does not exist, a new string value is created. The string is grown to make sure it can hold a bit at offset. The offset argument is required to be greater than or equal to 0, and smaller than 232 (this limits bitmaps to 512MB). When the string at key is grown, added bits are set to 0.

```C
//核心代码
/* SETBIT key offset bitvalue */
void setbitCommand(client *c) {
    robj *o;
    char *err = "bit is not an integer or out of range";
    size_t bitoffset;
    ssize_t byte, bit;
    int byteval, bitval;
    long on;

    if (getBitOffsetFromArgument(c,c->argv[2],&bitoffset,0,0) != C_OK)
        return;

    if (getLongFromObjectOrReply(c,c->argv[3],&on,err) != C_OK)
        return;

    /* Bits can only be set or cleared... */
    if (on & ~1) {
        addReplyError(c,err);
        return;
    }

    if ((o = lookupStringForBitCommand(c,bitoffset)) == NULL) return;

    /* Get current values */
    byte = bitoffset >> 3;
    byteval = ((uint8_t*)o->ptr)[byte];
    bit = 7 - (bitoffset & 0x7);
    bitval = byteval & (1 << bit);

    /* Update byte with new bit value and return original value */
    byteval &= ~(1 << bit);
    byteval |= ((on & 0x1) << bit);
    ((uint8_t*)o->ptr)[byte] = byteval;
}

/* This is an helper function for commands implementations that need to write
 * bits to a string object. The command creates or pad with zeroes the string
 * so that the 'maxbit' bit can be addressed. The object is finally
 * returned. Otherwise if the key holds a wrong type NULL is returned and
 * an error is sent to the client. */
robj *lookupStringForBitCommand(client *c, size_t maxbit) {
    size_t byte = maxbit >> 3;
    robj *o = lookupKeyWrite(c->db,c->argv[1]);

    if (o == NULL) {
        o = createObject(OBJ_STRING,sdsnewlen(NULL, byte+1));
        dbAdd(c->db,c->argv[1],o);
    } else {
        if (checkType(c,o,OBJ_STRING)) return NULL;
        o = dbUnshareStringValue(c->db,c->argv[1],o);
        o->ptr = sdsgrowzero(o->ptr,byte+1);
    }
    return o;
}

//大概总结：
// 1. 对传入的key 首先要保证有一个字符串(redisObject / robj)对象关联
// 2. 再计算一下byte = bitoffset >> 3 这个值，如100 的二进制为01100100，则byte 为01100 = 12。
// 3. 对字符串对象数组，12 这个位置的字节，取出来，并一下本次传入的bitoffset 的低3 位扩展到2 进制的值，如100 的低3 位为100 = 4，所以12 这个位置上，要并一下00010000。代码是 `byteval |= ((on & 0x1) << bit);`
// 4. 查询的时候，取出低三位二进制表示后的那个位的值。
```

### Redis 常见的性能问题和解决方法

1.Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。

2.Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。

3.Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

下面是我的一个实际项目的情况，大概情况是这样的：一个Master，4个Slave，没有Sharding机制，仅是读写分离，Master负责写入操作和AOF日志备份，AOF文件大概5G，Slave负责读操作，当Master调用BGREWRITEAOF时，Master和Slave负载会突然陡增，Master的写入请求基本上都不响应了，持续了大概5分钟，Slave的读请求过也半无法及时响应，上面的情况本来不会也不应该发生的，是因为以前Master的这个机器是Slave，在上面有一个shell定时任务在每天的上午10点调用BGREWRITEAOF重写AOF文件，后来由于Master机器down了，就把备份的这个Slave切成Master了，但是这个定时任务忘记删除了，就导致了上面悲剧情况的发生，原因还是找了几天才找到的。

将no-appendfsync-on-rewrite的配置设为yes可以缓解这个问题，设置为yes表示rewrite期间对新写操作不fsync，暂时存在内存中，等rewrite完成后再写入。最好是不开启Master的AOF备份功能。

4.Redis主从复制的性能问题，第一次Slave向Master同步的实现是：Slave向Master发出同步请求，Master先dump出rdb文件，然后将rdb文件全量传输给slave，然后Master把缓存的命令转发给Slave，初次同步完成。第二次以及以后的同步实现是：Master将变量的快照直接实时依次发送给各个Slave。不管什么原因导致Slave和Master断开重连都会重复以上过程。Redis的主从复制是建立在内存快照的持久化基础上，只要有Slave就一定会有内存快照发生。虽然Redis宣称主从复制无阻塞，但由于磁盘io的限制，如果Master快照文件比较大，那么dump会耗费比较长的时间，这个过程中Master可能无法响应请求，也就是说服务会中断，对于关键服务，这个后果也是很可怕的。

以上1.2.3.4根本问题的原因都离不开系统io瓶颈问题，也就是硬盘读写速度不够快，主进程 fsync()/write() 操作被阻塞。

5.单点故障问题，由于目前Redis的主从复制还不够成熟，所以存在明显的单点故障问题，这个目前只能自己做方案解决，如：主动复制，Proxy实现Slave对Master的替换等，这个也是Redis作者目前比较优先的任务之一，作者的解决方案思路简单优雅，详情可见 Redis Sentinel design draft http://redis.io/topics/sentinel-spec。

 

总结：

1.Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。

2.如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

3.为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。

4.尽量避免在压力较大的主库上增加从库

5.为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：`Master<--Slave1<--Slave2<--Slave3.......`，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果Master挂了，可以立马启用Slave1做Master，其他不变。

### 对比redis 和memcache （非常重要）

[原文](https://www.cnblogs.com/JavaBlackHole/p/7726195.html)

综合结论

应该说Memcached和Redis都能很好的满足解决我们的问题，它们性能都很高，总的来说，可以把Redis理解为是对Memcached的拓展，是更加重量级的实现，提供了更多更强大的功能。具体来说：

1.性能上： 
性能上都很出色，具体到细节，由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比 
Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。

2.内存空间和数据量大小： 
MemCached可以修改最大内存，采用LRU算法。Redis增加了VM的特性，突破了物理内存的限制。

3.操作便利上： 
MemCached数据结构单一，仅用来缓存数据，而Redis支持更加丰富的数据类型，也可以在服务器端直接对数据进行丰富的操作,这样可以减少网络IO次数和数据体积。

4.可靠性上： 
MemCached不支持数据持久化，断电或重启后数据消失，但其稳定性是有保证的。Redis支持数据持久化和数据恢复，允许单点故障，但是同时也会付出性能的代价。

5.应用场景： 
Memcached：动态系统中减轻数据库负载，提升性能；做缓存，适合多读少写，大数据量的情况（如人人网大量查询用户信息、好友信息、文章信息等）。 
Redis：适用于对读写效率要求都很高，数据处理业务复杂和对安全性要求较高的系统（如新浪微博的计数和微博发布部分系统，对数据安全性、读写要求都很高）。

需要慎重考虑的部分 
1.Memcached单个key-value大小有限，一个value最大只支持1MB，而Redis最大支持512MB 
2.Memcached只是个内存缓存，对可靠性无要求；而Redis更倾向于内存数据库，因此对对可靠性方面要求比较高 
3.从本质上讲，Memcached只是一个单一key-value内存Cache；而Redis则是一个数据结构内存数据库，支持五种数据类型，因此Redis除单纯缓存作用外，还可以处理一些简单的逻辑运算，Redis不仅可以缓存，而且还可以作为数据库用 
4.新版本（3.0）的Redis是指集群分布式，也就是说集群本身均衡客户端请求，各个节点可以交流，可拓展行、可维护性更强大。

#### 补充
在Redis中，并不是所有的数据都一直存储在内存中的，这是和Memcache相比一个最大的区别之一的。
还有这个Redis在很多方面具备数据库的特征的，或者说就是一个数据库系统，而Memcache只是简单的K/V缓存的。
他们的扩展都需要做集群；实现方式：master-slave、Hash的。，不过在100k以上的数据中，Memcache性能要高于Redis的。
如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis的，因为这两个特性Memcache都不具备的。
所以即使你只是希望在升级或者重启系统后缓存数据不会丢失的，选择Redis也是明智的选择得的。
还有虽然这个Redis和Memcache在写入性能上面差别不大的，读取性能上面尤其是批量读取性能上面Memcache更强的。
以上区别说明：memcache还是有可取之处的！！！
Memcache可以利用多核优势的，单实例吞吐量极高的，可以达到几十万QPS,适用于最大程度扛量的的。
他的话只支持简单的key/value数据结构的，不像Redis可以支持丰富的数据类型的。
无法进行持久化，数据不能备份，只能用于缓存使用，而且且重启后数据全部丢失的

### redis 常见35 问题
[原文](https://blog.csdn.net/chinahuyong/article/details/82683155)

### redis watch 

[原文](https://www.jianshu.com/p/ad273642b3bb)
我们常用redis的watch和multi来处理一些涉及并发的操作，redis的watch+multi实际是一种乐观锁，今天我们来分析一下它的实现机制。

```
$key = 'xxxx';
$redis->watch($key);
$redis->multi();
// 更新了key
$redis->set($key);
$flag = $redis->exec();

// 如果事务执行失败返回false
if ($flag === false) {
    
} else {
    
}
```
当客户端A和客户端B同时执行这段代码时候，因为事务的执行是串行的，假设A客户端先于B执行，那么当A执行完成时，会将客户端A从watch了这个key的列表中删除，并且将列表中的所有客户端都设置为CLIENT_DIRTY_CAS，之后当B执行的时候，事务发现B的状态是CLIENT_DIRTY_CAS，便终止事务并返回失败。

```shell
127.0.0.1:6379[1]> watch test2
OK
127.0.0.1:6379[1]> multi
OK
127.0.0.1:6379[1]> incr test2
QUEUED
127.0.0.1:6379[1]> exec
1) (integer) 7
127.0.0.1:6379[1]> watch test2
OK
127.0.0.1:6379[1]> multi
OK
127.0.0.1:6379[1]> incr test2
QUEUED
127.0.0.1:6379[1]> exec
(nil)
127.0.0.1:6379[1]>
```
代码：
```c
/* exec 命令 */
void execCommand(client *c) {
    int j;
    robj **orig_argv;
    int orig_argc;
    struct redisCommand *orig_cmd;
    int must_propagate = 0; /* Need to propagate MULTI/EXEC to AOF / slaves? */
    int was_master = server.masterhost == NULL;
    
    // 未执行multi，则返回
    if (!(c->flags & CLIENT_MULTI)) {
        addReplyError(c,"EXEC without MULTI");
        return;
    }
    
    /*
     * 关键
     * 处理客户端状态 以下两种状态会直接终止事务，不会执行事务队列中的命令
     * 1. CLIENT_DIRTY_CAS => 当因为watch的key被touch了
     * 2. CLIENT_DIRTY_EXEC => 当客户端入队了不存在的命令
     */
    
    /* Check if we need to abort the EXEC because:
     * 1) Some WATCHed key was touched.
     * 2) There was a previous error while queueing commands.
     * A failed EXEC in the first case returns a multi bulk nil object
     * (technically it is not an error but a special behavior), while
     * in the second an EXECABORT error is returned. */
    if (c->flags & (CLIENT_DIRTY_CAS|CLIENT_DIRTY_EXEC)) {
        addReply(c, c->flags & CLIENT_DIRTY_EXEC ? shared.execaborterr :
                                                  shared.nullmultibulk);
        // 
        discardTransaction(c);
        goto handle_monitor;
    }

    /* 执行队列中的命令 */
    // 清空当前客户端中存储的watch了的key，和hash表中客户端node
    unwatchAllKeys(c); /* Unwatch ASAP otherwise we'll waste CPU cycles */
    orig_argv = c->argv;
    orig_argc = c->argc;
    orig_cmd = c->cmd;
    addReplyMultiBulkLen(c,c->mstate.count);
    // 执行队列中的命令
    for (j = 0; j < c->mstate.count; j++) {
    }
}
```

在set 一些值的时候，会把flag 标识为CLIENT_DIRDY_CAS
```c
void setKey(redisDb *db, robj *key, robj *val) {
    if (lookupKeyWrite(db,key) == NULL) {
        dbAdd(db,key,val);
    } else {
        dbOverwrite(db,key,val);
    }
    incrRefCount(val);
    removeExpire(db,key);
    // 看这里👀 标记hash表中所有已经watch这个key的所有客户端状态为CLIENT_DIRTY_CAS
    // 如果我原先的值为1，这里set为1，也会执行这个方法。所以说和值变没变没关系。
    signalModifiedKey(db,key);
}

void signalModifiedKey(redisDb *db, robj *key) {
    touchWatchedKey(db,key);
}

/* 更新hash表中相应客户端的状态为CLIENT_DIRTY_CAS */
void touchWatchedKey(redisDb *db, robj *key) {
    list *clients;
    listIter li;
    listNode *ln;

    if (dictSize(db->watched_keys) == 0) return;
    clients = dictFetchValue(db->watched_keys, key);
    if (!clients) return;

    /* Mark all the clients watching this key as CLIENT_DIRTY_CAS */
    /* Check if we are already watching for this key */
    listRewind(clients,&li);
    while((ln = listNext(&li))) {
        client *c = listNodeValue(ln);

        c->flags |= CLIENT_DIRTY_CAS;
    }
}
```

### Redis为什么这么快

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路I/O复用模型，非阻塞IO；

5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：

（1）多路 I/O 复用模型

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

**这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。**采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

### 那么为什么Redis是单线程的
我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

### cpu 因素
1、我们知道Redis是用"单线程-多路复用IO模型"来实现高性能的内存数据服务的，这种机制避免了使用锁，但是同时这种机制在进行sunion之类的比较耗时的命令时会使redis的并发下降。因为是单一线程，所以同一时刻只有一个操作在进行，所以，耗时的命令会导致并发的下降，不只是读并发，写并发也会下降。而单一线程也只能用到一个CPU核心，所以可以在同一个多核的服务器中，可以启动多个实例，组成master-master或者master-slave的形式，耗时的读命令可以完全在slave进行。

需要改的redis.conf项：

pidfile /var/run/redis/redis_6377.pid  #pidfile要加上端口号
port 6377  #这个是必须改的
logfile /var/log/redis/redis_6377.log #logfile的名称也加上端口号
dbfilename dump_6377.rdb  #rdbfile也加上端口号

2、“我们不能任由操作系统负载均衡，因为我们自己更了解自己的程序，所以，我们可以手动地为其分配CPU核，而不会过多地占用CPU，或是让我们关键进程和一堆别的进程挤在一起。”。
CPU 是一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU， 而不是多核

在多核 CPU 服务器上面，Redis 的性能还依赖NUMA 配置和处理器绑定位置。最明显的影响是 redis-benchmark 会随机使用CPU内核。为了获得精准的结果，需要使用固定处理器工具（在 Linux 上可以使用 taskset）。最有效的办法是将客户端和服务端分离到两个不同的 CPU 来高校使用三级缓存。

### 常见线程模型

1、单进程多线程模型：MySQL、Memcached、Oracle（Windows版本）；

2、多进程模型：Oracle（Linux版本）；

3、Nginx有两类进程，一类称为Master进程(相当于管理进程)，另一类称为Worker进程（实际工作进程）。启动方式有两种：

（1）单进程启动：此时系统中仅有一个进程，该进程既充当Master进程的角色，也充当Worker进程的角色。

（2）多进程启动：此时系统有且仅有一个Master进程，至少有一个Worker进程工作。

（3）Master进程主要进行一些全局性的初始化工作和管理Worker的工作；事件处理是在Worker中进行的。
